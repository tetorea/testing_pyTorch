{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting CNN for an image classifier\n",
    "\n",
    "The aim is to detect the variety of the flower in the image amongst the varieties available in French Polynesia.\n",
    "The image database is handmade (and thus quite small...) : Google + own pictures\n",
    "\n",
    "In order to test different architectures, the neural net definition is simplified using a list with keywords. \n",
    "The neural net is then constructed automatically using this simplified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NbEpochsMax = 3\n",
    "BatchSize = 4\n",
    "NumWorkers = 4\n",
    "InImgSize = 32\n",
    "LearningRate = 0.003\n",
    "TrainImgPath = \"./imagesFlower/train/\"\n",
    "TestImgPath = \"./imagesFlower/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mean and std values for normalization based on the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5167, 0.5032, 0.3885])\n",
      "tensor([0.2929, 0.2576, 0.2955])\n"
     ]
    }
   ],
   "source": [
    "imgTransf = transforms.Compose([\n",
    "    transforms.Resize(InImgSize),\n",
    "    transforms.CenterCrop(InImgSize),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "imgSet = torchvision.datasets.ImageFolder(root=TrainImgPath, transform=imgTransf)\n",
    "imgLoader = data.DataLoader( imgSet, batch_size=BatchSize, shuffle=False,  num_workers=NumWorkers)\n",
    "\n",
    "image_means = torch.stack([sample.mean(1).mean(1) for sample, target in imgSet])\n",
    "image_means = image_means.mean(0)\n",
    "print( image_means )\n",
    "\n",
    "image_std = torch.stack([sample.view(sample.size(0),-1).std(1) for sample, target in imgSet])\n",
    "image_std = image_std.mean(0)\n",
    "print( image_std )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the images with the correct normalization and checking the available classes and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb train samples:  46\n",
      "Nb test samples:  10\n",
      "Detected Classes :  {'tiare': 0, 'tipanie': 1}\n"
     ]
    }
   ],
   "source": [
    "imgTransform = transforms.Compose([\n",
    "    transforms.Resize(InImgSize),\n",
    "    transforms.CenterCrop(InImgSize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( mean=image_means, std=image_std )\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=TrainImgPath, transform=imgTransform)\n",
    "trainloader = data.DataLoader(trainset, batch_size=BatchSize, shuffle=True,  num_workers=NumWorkers)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=TestImgPath, transform=imgTransform)\n",
    "testloader  = data.DataLoader(testset, batch_size=BatchSize, shuffle=True, num_workers=NumWorkers) \n",
    "\n",
    "print(\"Nb train samples: \", len(trainset))\n",
    "print(\"Nb test samples: \", len(testset))\n",
    "print(\"Detected Classes : \", trainset.class_to_idx)\n",
    "\n",
    "nbClasses = len( trainset.class_to_idx )\n",
    "classes = list( trainset.class_to_idx.keys() ) #('tiare', 'tipanie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the min and max pixel values in the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_val =  2.069544553756714\n",
      "min_val =  -1.9533658027648926\n"
     ]
    }
   ],
   "source": [
    "max_val = -1.\n",
    "min_val = 1.\n",
    "for data in trainloader :\n",
    "    max_t = torch.max( data[0] )\n",
    "    min_t = torch.min( data[0] )\n",
    "    if max_t > max_val : max_val = max_t.item()\n",
    "    if min_t < min_val : min_val = min_t.item()\n",
    "print( \"max_val = \", max_val )\n",
    "print( \"min_val = \", min_val )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with a histogram-based layer.<br>\n",
    "To allow the gradient computation, it uses a gaussian based representation of the histogram bins.<br>\n",
    "The approach to use gaussians to approximate a discrete object in order to use the gradient was already used in my Humanoids'08 paper (A Next-Best-View Algorithm for Autonomous 3DObject Modeling by a Humanoid Robot) but the same approach has already been used for CNN for Caffe framework in http://dde.binghamton.edu/download/model_hist/ <br>\n",
    "<br>\n",
    "...will need to tweak this a little more to make it really useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianHistogram( nn.Module ):\n",
    "    def __init__( self, color_channel, nb_bin, min_v, max_v ):\n",
    "        super( GaussianHistogram, self ).__init__()\n",
    "        self.nb_bin = nb_bin\n",
    "        \n",
    "        # gaussian parameters\n",
    "        self.neg_inv_sq_sigma = -1.0/0.02  # -1 / sigmaÂ²\n",
    "        \n",
    "        self.means = torch.Tensor( nb_bin )  # centers of each gaussian for each histogram bin\n",
    "        interval = ( float(max_v) - float(min_v) ) / float( nb_bin )\n",
    "        for i in range( nb_bin ):\n",
    "            self.means[i] = float(min_v) + float(i)*interval + interval / 2.\n",
    "\n",
    "        # each histogram bin has a parameter to influence its importance, the optimizer will look for the best weights..\n",
    "        self.bin_weights = nn.Parameter( torch.rand( color_channel, nb_bin, requires_grad = True ) )\n",
    "        \n",
    "\n",
    "    def forward( self, x ):\n",
    "        # x.size() -> [4,3,32,32] = batch_size, nb_channels, width, height\n",
    "        # print( \"Size X for hist : \", x.size() )\n",
    "        nb_pixels = float( x.size(2)*x.size(3) )\n",
    "        hist = torch.Tensor( x.size(0), x.size(1), self.nb_bin ).to(device)\n",
    "\n",
    "        for b, x1 in enumerate( x ) :\n",
    "            for c, x2 in enumerate( x1 ) :\n",
    "                for h in range( self.nb_bin ):\n",
    "                    hist[b,c,h] = ( torch.exp( ( x2.sub( self.means[h] ) ).pow(2) * self.neg_inv_sq_sigma ) ).sum()\n",
    "            hist[b] *= self.bin_weights / nb_pixels\n",
    "            \n",
    "        # print( \"hist weights : \", self.bin_weights )\n",
    "        # return [batch_size, nb_channels, nb_bin]\n",
    "        return hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prototype faster we use a basic list to define a neural net architecture (basic CNN for now).\n",
    "Each element of the list represents a layer.\n",
    "Layers are defined in the order in which they are executed.\n",
    "Similar to nn.Sequential but slightly more compact (...but with less options now) and we don't have to compute all the numbers for input or output\n",
    "\n",
    "One layer is composed of a name and optionally some parameters.\n",
    "Currently available layers:\n",
    "- \"In\", number_of_input_for_the_next_layer. In Must be the first layer!\n",
    "- \"Conv2\", number_of_output, kernel_size\n",
    "- \"MaxPool2\", kernel_size\n",
    "- \"AvgPool2\", kernel_size\n",
    "- \"Drop\", probability\n",
    "- \"ReLu\"\n",
    "- \"View\"\n",
    "- \"Linear\", number_of_output\n",
    "- \"GaussHist\", color_channel, number of bins, min pixel value, max pixel value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self, netConfig ):\n",
    "        super(TestNet, self).__init__()\n",
    "        \n",
    "        self.netConfig = netConfig\n",
    "        imgw = InImgSize\n",
    "        imgh = InImgSize\n",
    "        self.func = nn.ModuleList()  # if declared as [], the parameters of the function are not stored and we get the error : optimizer got an empty parameter list\n",
    "        self.viewSize = None         # we consider only one view layer in the net, for now\n",
    "\n",
    "        currOutput = 0               # number of outputs in the last computed layer\n",
    "        viewMul = 1\n",
    "        \n",
    "        if netConfig[0][0] != \"In\":\n",
    "            print( \"Error : the first item in the net configuration must be In\")\n",
    "            return\n",
    "        # TODO : add more test to check consistency between layers\n",
    "        \n",
    "        # compute all necessary layers using the declared netConfig\n",
    "        for i,l in enumerate( netConfig ):\n",
    "            layerName = l[0]\n",
    "            param1 = None if len(l) < 2 else l[1]\n",
    "            if layerName == \"In\" and i==0 :\n",
    "                print( \"In : \", param1 )\n",
    "                currOutput = param1\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            elif layerName == \"GaussHist\" and len(l)>4 :\n",
    "                print( \"GaussHist : \", param1, \", \", l[2], \", \", l[3], \", \", l[4] )\n",
    "                self.func.append( GaussianHistogram( param1, l[2], l[3], l[4] ) )\n",
    "                currOutput = l[2]\n",
    "                viewMul = param1\n",
    "            elif layerName == \"Conv2\" and len(l)>2 :\n",
    "                print( \"Conv2 : \", currOutput,\",\", param1,\",\", l[2] )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.Conv2d( currOutput, param1, l[2] ) )\n",
    "                currOutput = param1\n",
    "                imgw = imgw - l[2] + 1\n",
    "                imgh = imgh - l[2] + 1\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"AvgPool2\" :\n",
    "                print( \"AvgPool2 : \", param1 )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.AvgPool2d( param1, param1 ) )\n",
    "                imgw = imgw / 2\n",
    "                imgh = imgh / 2\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"MaxPool2\" :\n",
    "                print( \"MaxPool2 : \", param1 )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.MaxPool2d( param1, param1 ) )\n",
    "                imgw = imgw / 2\n",
    "                imgh = imgh / 2\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"Drop\" :\n",
    "                print( \"Drop : \", param1 )\n",
    "                self.func.append( nn.Dropout( p=param1 ) )\n",
    "            elif layerName == \"Linear\" :\n",
    "                print( \"Linear : \", int(currOutput),\",\", int(param1) )\n",
    "                self.func.append( nn.Linear( int(currOutput), int(param1) ) )\n",
    "                currOutput = param1\n",
    "            elif layerName == \"ReLu\" :\n",
    "                print( \"ReLu\" )\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            elif layerName == \"View\" :\n",
    "                currOutput = currOutput * viewMul\n",
    "                print( \"View : \", -1, \",\", int(currOutput) )\n",
    "                self.viewSize = currOutput\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            else :\n",
    "                print( \"Unknown layer : \", layerName )\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i,layer in enumerate( self.netConfig ) :\n",
    "            if self.func[i] != None :\n",
    "                x = self.func[i]( x )\n",
    "            elif layer[0] == \"View\" :\n",
    "                x = x.view( -1, int(self.viewSize) )\n",
    "            elif layer[0] == \"ReLu\" :\n",
    "                x = F.relu( x )\n",
    "            elif layer[0] == \"In\" :\n",
    "                None\n",
    "            else :\n",
    "                print(\"Unknown Function..\")\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    [[\"In\",3],\n",
    "    [\"GaussHist\",3,10,min_val,max_val],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"GaussHist\",10,10,0.,1.],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"GaussHist\",10,20,0.,1.],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",80],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",40],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",20],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"Drop\",0.1],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",50],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",40],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "    \n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,5],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",80],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In :  3\n",
      "GaussHist :  3 ,  10 ,  -1.9533658027648926 ,  2.069544553756714\n",
      "View :  -1 , 30\n",
      "Linear :  30 , 60\n",
      "ReLu\n",
      "Linear :  60 , 30\n",
      "ReLu\n",
      "Linear :  30 , 2\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    0] loss: 0.703\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    1] loss: 0.700\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    2] loss: 0.647\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    3] loss: 0.748\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    4] loss: 0.700\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    5] loss: 0.743\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    6] loss: 0.654\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    7] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    8] loss: 0.624\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,    9] loss: 0.695\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   0,   10] loss: 0.657\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   0,   11] loss: 0.779\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   0] acc: 50.000 -- time: 5\n",
      "Backing up the network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type TestNet. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\torch\\serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GaussianHistogram. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    0] loss: 0.609\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    1] loss: 0.741\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    2] loss: 0.650\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    3] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    4] loss: 0.739\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    5] loss: 0.733\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    6] loss: 0.652\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    7] loss: 0.737\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    8] loss: 0.651\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,    9] loss: 0.697\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   1,   10] loss: 0.651\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   1,   11] loss: 0.697\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   1] acc: 50.000 -- time: 10\n",
      "Backing up the network...\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    0] loss: 0.657\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    1] loss: 0.649\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    2] loss: 0.728\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    3] loss: 0.697\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    4] loss: 0.689\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    5] loss: 0.649\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    6] loss: 0.729\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    7] loss: 0.654\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    8] loss: 0.731\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,    9] loss: 0.692\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "[Epoch   2,   10] loss: 0.683\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   2,   11] loss: 0.609\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([4, 3, 32, 32])\n",
      "Size de X pour hist :  torch.Size([2, 3, 32, 32])\n",
      "[Epoch   2] acc: 50.000 -- time: 15\n",
      "Backing up the network...\n",
      "Architecture 0 training finished -- 0m 16s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "GaussHist :  10 ,  10 ,  0.0 ,  1.0\n",
      "View :  -1 , 100\n",
      "Linear :  100 , 60\n",
      "ReLu\n",
      "Linear :  60 , 30\n",
      "ReLu\n",
      "Linear :  30 , 2\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    0] loss: 0.707\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    1] loss: 0.697\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    2] loss: 0.703\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    3] loss: 0.706\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    4] loss: 0.683\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    5] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    6] loss: 0.708\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    7] loss: 0.705\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    8] loss: 0.709\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    9] loss: 0.692\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,   10] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   0,   11] loss: 0.689\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   0] acc: 50.000 -- time: 10\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    0] loss: 0.676\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    1] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    2] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    3] loss: 0.729\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    4] loss: 0.652\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    5] loss: 0.710\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    6] loss: 0.690\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    7] loss: 0.691\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    8] loss: 0.708\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    9] loss: 0.690\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,   10] loss: 0.643\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   1,   11] loss: 0.685\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   1] acc: 50.000 -- time: 19\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    0] loss: 0.706\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    1] loss: 0.661\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    2] loss: 0.660\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    3] loss: 0.693\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    4] loss: 0.708\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    5] loss: 0.676\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    6] loss: 0.653\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    7] loss: 0.684\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    8] loss: 0.658\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    9] loss: 0.641\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,   10] loss: 0.697\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   2,   11] loss: 0.755\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   2] acc: 50.000 -- time: 29\n",
      "Architecture 1 training finished -- 0m 29s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "GaussHist :  10 ,  20 ,  0.0 ,  1.0\n",
      "View :  -1 , 200\n",
      "Linear :  200 , 60\n",
      "ReLu\n",
      "Linear :  60 , 30\n",
      "ReLu\n",
      "Linear :  30 , 2\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    0] loss: 0.678\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    1] loss: 0.694\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    2] loss: 0.735\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    3] loss: 0.727\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    4] loss: 0.670\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    5] loss: 0.673\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    6] loss: 0.686\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    7] loss: 0.675\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    8] loss: 0.663\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,    9] loss: 0.731\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   0,   10] loss: 0.688\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   0,   11] loss: 0.692\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   0] acc: 50.000 -- time: 14\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    0] loss: 0.642\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    1] loss: 0.681\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    2] loss: 0.637\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    3] loss: 0.690\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    4] loss: 0.682\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    5] loss: 0.724\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    6] loss: 0.639\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    7] loss: 0.670\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    8] loss: 0.683\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   1,    9] loss: 0.676\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   1,   10] loss: 0.657\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   1,   11] loss: 0.649\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   1] acc: 50.000 -- time: 29\n",
      "Backing up the network...\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    0] loss: 0.611\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    1] loss: 0.609\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    2] loss: 0.550\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    3] loss: 0.630\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    4] loss: 0.600\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    5] loss: 0.789\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    6] loss: 0.606\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    7] loss: 0.559\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    8] loss: 0.611\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,    9] loss: 0.778\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "[Epoch   2,   10] loss: 0.686\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   2,   11] loss: 0.640\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([4, 10, 15, 15])\n",
      "Size de X pour hist :  torch.Size([2, 10, 15, 15])\n",
      "[Epoch   2] acc: 80.000 -- time: 44\n",
      "Backing up the network...\n",
      "Architecture 2 training finished -- 0m 44s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "View :  -1 , 2250\n",
      "Linear :  2250 , 60\n",
      "ReLu\n",
      "Linear :  60 , 30\n",
      "ReLu\n",
      "Linear :  30 , 2\n",
      "[Epoch   0,    0] loss: 0.665\n",
      "[Epoch   0,    1] loss: 0.707\n",
      "[Epoch   0,    2] loss: 0.569\n",
      "[Epoch   0,    3] loss: 0.788\n",
      "[Epoch   0,    4] loss: 0.378\n",
      "[Epoch   0,    5] loss: 0.973\n",
      "[Epoch   0,    6] loss: 0.954\n",
      "[Epoch   0,    7] loss: 0.477\n",
      "[Epoch   0,    8] loss: 0.570\n",
      "[Epoch   0,    9] loss: 1.044\n",
      "[Epoch   0,   10] loss: 0.882\n",
      "[Epoch   0,   11] loss: 0.648\n",
      "[Epoch   0] acc: 80.000 -- time: 4\n",
      "[Epoch   1,    0] loss: 0.548\n",
      "[Epoch   1,    1] loss: 0.464\n",
      "[Epoch   1,    2] loss: 0.361\n",
      "[Epoch   1,    3] loss: 0.618\n",
      "[Epoch   1,    4] loss: 0.795\n",
      "[Epoch   1,    5] loss: 0.752\n",
      "[Epoch   1,    6] loss: 0.617\n",
      "[Epoch   1,    7] loss: 0.193\n",
      "[Epoch   1,    8] loss: 0.355\n",
      "[Epoch   1,    9] loss: 0.295\n",
      "[Epoch   1,   10] loss: 0.419\n",
      "[Epoch   1,   11] loss: 0.302\n",
      "[Epoch   1] acc: 100.000 -- time: 9\n",
      "Backing up the network...\n",
      "[Epoch   2,    0] loss: 0.364\n",
      "[Epoch   2,    1] loss: 0.435\n",
      "[Epoch   2,    2] loss: 0.243\n",
      "[Epoch   2,    3] loss: 0.356\n",
      "[Epoch   2,    4] loss: 0.061\n",
      "[Epoch   2,    5] loss: 0.136\n",
      "[Epoch   2,    6] loss: 0.165\n",
      "[Epoch   2,    7] loss: 0.093\n",
      "[Epoch   2,    8] loss: 0.206\n",
      "[Epoch   2,    9] loss: 0.083\n",
      "[Epoch   2,   10] loss: 0.052\n",
      "[Epoch   2,   11] loss: 0.079\n",
      "[Epoch   2] acc: 100.000 -- time: 13\n",
      "Backing up the network...\n",
      "Architecture 3 training finished -- 0m 14s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "View :  -1 , 2250\n",
      "Linear :  2250 , 80\n",
      "ReLu\n",
      "Linear :  80 , 60\n",
      "ReLu\n",
      "Linear :  60 , 2\n",
      "[Epoch   0,    0] loss: 0.671\n",
      "[Epoch   0,    1] loss: 0.141\n",
      "[Epoch   0,    2] loss: 4.091\n",
      "[Epoch   0,    3] loss: 1.348\n",
      "[Epoch   0,    4] loss: 0.836\n",
      "[Epoch   0,    5] loss: 0.669\n",
      "[Epoch   0,    6] loss: 0.681\n",
      "[Epoch   0,    7] loss: 0.882\n",
      "[Epoch   0,    8] loss: 0.645\n",
      "[Epoch   0,    9] loss: 0.666\n",
      "[Epoch   0,   10] loss: 0.546\n",
      "[Epoch   0,   11] loss: 0.734\n",
      "[Epoch   0] acc: 60.000 -- time: 4\n",
      "[Epoch   1,    0] loss: 0.776\n",
      "[Epoch   1,    1] loss: 0.622\n",
      "[Epoch   1,    2] loss: 0.760\n",
      "[Epoch   1,    3] loss: 0.587\n",
      "[Epoch   1,    4] loss: 0.566\n",
      "[Epoch   1,    5] loss: 0.576\n",
      "[Epoch   1,    6] loss: 0.572\n",
      "[Epoch   1,    7] loss: 0.574\n",
      "[Epoch   1,    8] loss: 0.519\n",
      "[Epoch   1,    9] loss: 0.461\n",
      "[Epoch   1,   10] loss: 0.432\n",
      "[Epoch   1,   11] loss: 0.434\n",
      "[Epoch   1] acc: 90.000 -- time: 9\n",
      "[Epoch   2,    0] loss: 0.324\n",
      "[Epoch   2,    1] loss: 0.422\n",
      "[Epoch   2,    2] loss: 0.299\n",
      "[Epoch   2,    3] loss: 0.274\n",
      "[Epoch   2,    4] loss: 0.241\n",
      "[Epoch   2,    5] loss: 0.247\n",
      "[Epoch   2,    6] loss: 0.384\n",
      "[Epoch   2,    7] loss: 0.488\n",
      "[Epoch   2,    8] loss: 0.241\n",
      "[Epoch   2,    9] loss: 0.070\n",
      "[Epoch   2,   10] loss: 0.142\n",
      "[Epoch   2,   11] loss: 0.505\n",
      "[Epoch   2] acc: 100.000 -- time: 14\n",
      "Architecture 4 training finished -- 0m 14s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "View :  -1 , 2250\n",
      "Linear :  2250 , 40\n",
      "ReLu\n",
      "Linear :  40 , 30\n",
      "ReLu\n",
      "Linear :  30 , 20\n",
      "ReLu\n",
      "Linear :  20 , 2\n",
      "[Epoch   0,    0] loss: 0.693\n",
      "[Epoch   0,    1] loss: 0.692\n",
      "[Epoch   0,    2] loss: 0.756\n",
      "[Epoch   0,    3] loss: 0.603\n",
      "[Epoch   0,    4] loss: 0.721\n",
      "[Epoch   0,    5] loss: 0.623\n",
      "[Epoch   0,    6] loss: 0.592\n",
      "[Epoch   0,    7] loss: 0.628\n",
      "[Epoch   0,    8] loss: 0.764\n",
      "[Epoch   0,    9] loss: 0.685\n",
      "[Epoch   0,   10] loss: 0.622\n",
      "[Epoch   0,   11] loss: 0.661\n",
      "[Epoch   0] acc: 50.000 -- time: 4\n",
      "[Epoch   1,    0] loss: 0.474\n",
      "[Epoch   1,    1] loss: 0.429\n",
      "[Epoch   1,    2] loss: 0.284\n",
      "[Epoch   1,    3] loss: 0.721\n",
      "[Epoch   1,    4] loss: 0.186\n",
      "[Epoch   1,    5] loss: 0.678\n",
      "[Epoch   1,    6] loss: 1.150\n",
      "[Epoch   1,    7] loss: 0.446\n",
      "[Epoch   1,    8] loss: 0.427\n",
      "[Epoch   1,    9] loss: 0.160\n",
      "[Epoch   1,   10] loss: 0.272\n",
      "[Epoch   1,   11] loss: 0.392\n",
      "[Epoch   1] acc: 80.000 -- time: 9\n",
      "[Epoch   2,    0] loss: 0.327\n",
      "[Epoch   2,    1] loss: 0.394\n",
      "[Epoch   2,    2] loss: 0.198\n",
      "[Epoch   2,    3] loss: 0.107\n",
      "[Epoch   2,    4] loss: 0.226\n",
      "[Epoch   2,    5] loss: 0.291\n",
      "[Epoch   2,    6] loss: 0.168\n",
      "[Epoch   2,    7] loss: 0.607\n",
      "[Epoch   2,    8] loss: 0.088\n",
      "[Epoch   2,    9] loss: 0.022\n",
      "[Epoch   2,   10] loss: 0.015\n",
      "[Epoch   2,   11] loss: 0.035\n",
      "[Epoch   2] acc: 100.000 -- time: 14\n",
      "Architecture 5 training finished -- 0m 15s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "Drop :  0.1\n",
      "View :  -1 , 2250\n",
      "Linear :  2250 , 50\n",
      "ReLu\n",
      "Linear :  50 , 40\n",
      "ReLu\n",
      "Linear :  40 , 2\n",
      "[Epoch   0,    0] loss: 0.701\n",
      "[Epoch   0,    1] loss: 0.696\n",
      "[Epoch   0,    2] loss: 0.660\n",
      "[Epoch   0,    3] loss: 0.623\n",
      "[Epoch   0,    4] loss: 0.568\n",
      "[Epoch   0,    5] loss: 0.826\n",
      "[Epoch   0,    6] loss: 0.689\n",
      "[Epoch   0,    7] loss: 0.592\n",
      "[Epoch   0,    8] loss: 0.698\n",
      "[Epoch   0,    9] loss: 0.315\n",
      "[Epoch   0,   10] loss: 0.664\n",
      "[Epoch   0,   11] loss: 0.312\n",
      "[Epoch   0] acc: 80.000 -- time: 4\n",
      "[Epoch   1,    0] loss: 0.342\n",
      "[Epoch   1,    1] loss: 0.372\n",
      "[Epoch   1,    2] loss: 0.157\n",
      "[Epoch   1,    3] loss: 0.591\n",
      "[Epoch   1,    4] loss: 0.158\n",
      "[Epoch   1,    5] loss: 0.201\n",
      "[Epoch   1,    6] loss: 0.380\n",
      "[Epoch   1,    7] loss: 0.173\n",
      "[Epoch   1,    8] loss: 0.304\n",
      "[Epoch   1,    9] loss: 0.100\n",
      "[Epoch   1,   10] loss: 0.553\n",
      "[Epoch   1,   11] loss: 0.000\n",
      "[Epoch   1] acc: 80.000 -- time: 9\n",
      "[Epoch   2,    0] loss: 0.027\n",
      "[Epoch   2,    1] loss: 0.110\n",
      "[Epoch   2,    2] loss: 0.008\n",
      "[Epoch   2,    3] loss: 0.046\n",
      "[Epoch   2,    4] loss: 0.003\n",
      "[Epoch   2,    5] loss: 0.007\n",
      "[Epoch   2,    6] loss: 0.000\n",
      "[Epoch   2,    7] loss: 0.343\n",
      "[Epoch   2,    8] loss: 0.023\n",
      "[Epoch   2,    9] loss: 0.003\n",
      "[Epoch   2,   10] loss: 0.017\n",
      "[Epoch   2,   11] loss: 0.001\n",
      "[Epoch   2] acc: 100.000 -- time: 14\n",
      "Backing up the network...\n",
      "Architecture 6 training finished -- 0m 15s\n",
      "In :  3\n",
      "Conv2 :  3 , 10 , 5\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "Conv2 :  10 , 10 , 3\n",
      "ReLu\n",
      "MaxPool2 :  2\n",
      "View :  -1 , 360\n",
      "Linear :  360 , 80\n",
      "ReLu\n",
      "Linear :  80 , 60\n",
      "ReLu\n",
      "Linear :  60 , 2\n",
      "[Epoch   0,    0] loss: 0.692\n",
      "[Epoch   0,    1] loss: 0.661\n",
      "[Epoch   0,    2] loss: 0.672\n",
      "[Epoch   0,    3] loss: 0.556\n",
      "[Epoch   0,    4] loss: 0.971\n",
      "[Epoch   0,    5] loss: 1.048\n",
      "[Epoch   0,    6] loss: 0.696\n",
      "[Epoch   0,    7] loss: 0.652\n",
      "[Epoch   0,    8] loss: 0.650\n",
      "[Epoch   0,    9] loss: 0.676\n",
      "[Epoch   0,   10] loss: 0.670\n",
      "[Epoch   0,   11] loss: 0.675\n",
      "[Epoch   0] acc: 100.000 -- time: 5\n",
      "[Epoch   1,    0] loss: 0.664\n",
      "[Epoch   1,    1] loss: 0.640\n",
      "[Epoch   1,    2] loss: 0.647\n",
      "[Epoch   1,    3] loss: 0.632\n",
      "[Epoch   1,    4] loss: 0.613\n",
      "[Epoch   1,    5] loss: 0.529\n",
      "[Epoch   1,    6] loss: 0.563\n",
      "[Epoch   1,    7] loss: 0.462\n",
      "[Epoch   1,    8] loss: 0.248\n",
      "[Epoch   1,    9] loss: 0.401\n",
      "[Epoch   1,   10] loss: 0.216\n",
      "[Epoch   1,   11] loss: 0.030\n",
      "[Epoch   1] acc: 90.000 -- time: 10\n",
      "[Epoch   2,    0] loss: 0.494\n",
      "[Epoch   2,    1] loss: 0.130\n",
      "[Epoch   2,    2] loss: 0.116\n",
      "[Epoch   2,    3] loss: 0.079\n",
      "[Epoch   2,    4] loss: 0.384\n",
      "[Epoch   2,    5] loss: 0.175\n",
      "[Epoch   2,    6] loss: 0.086\n",
      "[Epoch   2,    7] loss: 0.111\n",
      "[Epoch   2,    8] loss: 0.008\n",
      "[Epoch   2,    9] loss: 0.010\n",
      "[Epoch   2,   10] loss: 0.089\n",
      "[Epoch   2,   11] loss: 0.012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch   2] acc: 100.000 -- time: 14\n",
      "Architecture 7 training finished -- 0m 15s\n",
      "Reloading the best net :  6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestNet(\n",
       "  (func): ModuleList(\n",
       "    (0): None\n",
       "    (1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (2): None\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.1, inplace=False)\n",
       "    (5): None\n",
       "    (6): Linear(in_features=2250, out_features=50, bias=True)\n",
       "    (7): None\n",
       "    (8): Linear(in_features=50, out_features=40, bias=True)\n",
       "    (9): None\n",
       "    (10): Linear(in_features=40, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_architecture = 0\n",
    "best_acc = 0.0\n",
    "best_loss = 999\n",
    "\n",
    "for archi, netConfig in enumerate(architectures):\n",
    "    net = TestNet( netConfig )\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam( net.parameters(), lr=LearningRate )\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=LearningRate, momentum=0.9)\n",
    "\n",
    "    best_state = copy.deepcopy( net.state_dict() )\n",
    "    start_time = time.time()\n",
    "    for epoch in range( NbEpochsMax ):\n",
    "\n",
    "        # training phase \n",
    "        mean_loss = 0.\n",
    "        nb_mean = 0\n",
    "        for i, data in enumerate( trainloader, 0 ):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # print( \"parameters before : \", list( net.parameters() ) )\n",
    "\n",
    "            outputs = net( inputs )\n",
    "            loss = criterion( outputs, labels )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = loss.item()\n",
    "            mean_loss += running_loss\n",
    "            nb_mean += 1\n",
    "            \n",
    "            # print( \"parameters after : \", list( net.parameters() ) )\n",
    "            print('[Epoch %3d, %4d] loss: %.3f' % (epoch, i, running_loss) )\n",
    "\n",
    "        mean_loss /= float(nb_mean)\n",
    "        \n",
    "        # test phase\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net( images )\n",
    "                _, predicted = torch.max( outputs.data, 1 )\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            acc = 100 * correct / total\n",
    "            epoch_time = time.time() - start_time\n",
    "            print('[Epoch %3d] acc: %.3f -- time: %d' % (epoch, acc, epoch_time) )\n",
    "\n",
    "            if acc > best_acc or (acc == best_acc and mean_loss < best_loss):\n",
    "                print(\"Backing up the network...\")\n",
    "                best_acc = acc\n",
    "                best_loss = mean_loss\n",
    "                best_state = copy.deepcopy( net.state_dict() )\n",
    "                best_architecture = archi\n",
    "                torch.save( net, './TahitiFlowerBest.pt' )\n",
    "\n",
    "    computation_time = time.time() - start_time\n",
    "    print('Architecture {} training finished -- {:.0f}m {:.0f}s'.format( archi, computation_time // 60, computation_time % 60) )\n",
    "\n",
    "print(\"Reloading the best net : \", best_architecture )\n",
    "net = torch.load( './TahitiFlowerBest.pt' )\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  tipanie tiare tiare tipanie\n"
     ]
    }
   ],
   "source": [
    "def imshow( img ):\n",
    "    # need to put color channel at the end for matplotlib\n",
    "    image = img.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Un-normalize\n",
    "    image = np.array(image_std) * image + np.array(image_means)\n",
    "    \n",
    "    plt.imshow( image )\n",
    "    plt.show()\n",
    "\n",
    "# show all images in a batch\n",
    "dataiter = iter( testloader )\n",
    "images, labels = dataiter.next()\n",
    "imshow( torchvision.utils.make_grid(images) )\n",
    "\n",
    "print( 'GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(BatchSize)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  tipanie tiare tiare tipanie\n"
     ]
    }
   ],
   "source": [
    "outputs = net( images.to(device) )\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(BatchSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of tiare : 100 %\n",
      "Accuracy of tipanie : 100 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(nbClasses))\n",
    "class_total = list(0. for i in range(nbClasses))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(nbClasses):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(nbClasses):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterVisualizer():\n",
    "    def __init__(self, model, size=56, upscaling_steps=12, upscaling_factor=1.2):\n",
    "        self.size, self.upscaling_steps, self.upscaling_factor = size, upscaling_steps, upscaling_factor\n",
    "        self.model = model\n",
    "        for p in self.model.parameters(): p.requires_grad=False  # set_trainable(self.model, False)\n",
    "\n",
    "    def visualize(self, layer, filter, lr=0.1, opt_steps=20, blur=None):\n",
    "        sz = self.size\n",
    "        img = np.uint8(np.random.uniform(150, 180, (sz, sz, 3)))/255  # generate random image\n",
    "        activations = SaveFeatures(list(self.model.children())[layer])  # register hook\n",
    "\n",
    "        for _ in range(self.upscaling_steps):  # scale the image up upscaling_steps times\n",
    "            train_tfms, val_tfms = tfms_from_model(Net,sz) # vgg16, sz)\n",
    "            img_var = V(val_tfms(img)[None], requires_grad=True)  # convert image to Variable that requires grad\n",
    "            optimizer = torch.optim.Adam([img_var], lr=lr, weight_decay=1e-6)\n",
    "            for n in range(opt_steps):  # optimize pixel values for opt_steps times\n",
    "                optimizer.zero_grad()\n",
    "                self.model(img_var)\n",
    "                loss = -activations.features[0, filter].mean()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            img = val_tfms.denorm(img_var.data.cpu().numpy()[0].transpose(1,2,0))\n",
    "            self.output = img\n",
    "            sz = int(self.upscaling_factor * sz)  # calculate new image size\n",
    "            img = cv2.resize(img, (sz, sz), interpolation = cv2.INTER_CUBIC)  # scale image up\n",
    "            if blur is not None: img = cv2.blur(img,(blur,blur))  # blur image to reduce high frequency patterns\n",
    "        self.save(layer, filter)\n",
    "        activations.close()\n",
    "        \n",
    "    def save(self, layer, filter):\n",
    "        plt.imsave(\"layer_\"+str(layer)+\"_filter_\"+str(filter)+\".jpg\", np.clip(self.output, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FV = FilterVisualizer( net, size=56, upscaling_steps=12, upscaling_factor=1.2)\n",
    "# FV.visualize( 2, 265, blur=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "- https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "- https://medium.com/datadriveninvestor/creating-a-pytorch-image-classifier-da9db139ba80\n",
    "- http://dde.binghamton.edu/download/model_hist/\n",
    "- ...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
