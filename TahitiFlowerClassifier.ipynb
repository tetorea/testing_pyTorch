{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting CNN for an image classifier\n",
    "\n",
    "The aim is to detect the variety of the flower in the image amongst the varieties available in French Polynesia.\n",
    "The image database is handmade (and thus quite small...) : Google + own pictures\n",
    "\n",
    "In order to test different architectures, the neural net definition is simplified using a list with keywords. \n",
    "The neural net is then constructed automatically using this simplified format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NbEpochsMax = 3\n",
    "BatchSize = 4\n",
    "NumWorkers = 4\n",
    "InImgSize = 32\n",
    "LearningRate = 0.003\n",
    "TrainImgPath = \"./imagesFlower/train/\"\n",
    "TestImgPath = \"./imagesFlower/test/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the mean and std values for normalization based on the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTransf = transforms.Compose([\n",
    "    transforms.Resize(InImgSize),\n",
    "    transforms.CenterCrop(InImgSize),\n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "imgSet = torchvision.datasets.ImageFolder(root=TrainImgPath, transform=imgTransf)\n",
    "imgLoader = data.DataLoader( imgSet, batch_size=BatchSize, shuffle=False,  num_workers=NumWorkers)\n",
    "\n",
    "image_means = torch.stack([sample.mean(1).mean(1) for sample, target in imgSet])\n",
    "image_means = image_means.mean(0)\n",
    "print( image_means )\n",
    "\n",
    "image_std = torch.stack([sample.view(sample.size(0),-1).std(1) for sample, target in imgSet])\n",
    "image_std = image_std.mean(0)\n",
    "print( image_std )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the images with the correct normalization and checking the available classes and number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTransform = transforms.Compose([\n",
    "    transforms.Resize(InImgSize),\n",
    "    transforms.CenterCrop(InImgSize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize( mean=image_means, std=image_std )\n",
    "    ])\n",
    "\n",
    "trainset = torchvision.datasets.ImageFolder(root=TrainImgPath, transform=imgTransform)\n",
    "trainloader = data.DataLoader(trainset, batch_size=BatchSize, shuffle=True,  num_workers=NumWorkers)\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(root=TestImgPath, transform=imgTransform)\n",
    "testloader  = data.DataLoader(testset, batch_size=BatchSize, shuffle=True, num_workers=NumWorkers) \n",
    "\n",
    "print(\"Nb train samples: \", len(trainset))\n",
    "print(\"Nb test samples: \", len(testset))\n",
    "print(\"Detected Classes : \", trainset.class_to_idx)\n",
    "\n",
    "nbClasses = len( trainset.class_to_idx )\n",
    "classes = list( trainset.class_to_idx.keys() ) #('tiare', 'tipanie')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the min and max pixel values in the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val = -1.\n",
    "min_val = 1.\n",
    "for data in trainloader :\n",
    "    max_t = torch.max( data[0] )\n",
    "    min_t = torch.min( data[0] )\n",
    "    if max_t > max_val : max_val = max_t.item()\n",
    "    if min_t < min_val : min_val = min_t.item()\n",
    "print( \"max_val = \", max_val )\n",
    "print( \"min_val = \", min_val )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting with a histogram-based layer.<br>\n",
    "To allow the gradient computation, it uses a gaussian based representation of the histogram bins.<br>\n",
    "The approach to use gaussians to approximate a discrete object in order to use the gradient was already used in my Humanoids'08 paper (A Next-Best-View Algorithm for Autonomous 3DObject Modeling by a Humanoid Robot) but the same approach has already been used for CNN for Caffe framework in http://dde.binghamton.edu/download/model_hist/ <br>\n",
    "<br>\n",
    "...will need to tweak this a little more to make it really useful..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianHistogram( nn.Module ):\n",
    "    def __init__( self, color_channel, nb_bin, min_v, max_v ):\n",
    "        super( GaussianHistogram, self ).__init__()\n",
    "        self.nb_bin = nb_bin\n",
    "        \n",
    "        # gaussian parameters\n",
    "        self.neg_inv_sq_sigma = -1.0/0.02  # -1 / sigmaÂ²\n",
    "        \n",
    "        self.means = torch.Tensor( nb_bin )  # centers of each gaussian for each histogram bin\n",
    "        interval = ( float(max_v) - float(min_v) ) / float( nb_bin )\n",
    "        for i in range( nb_bin ):\n",
    "            self.means[i] = float(min_v) + float(i)*interval + interval / 2.\n",
    "\n",
    "        # each histogram bin has a parameter to influence its importance, the optimizer will look for the best weights..\n",
    "        self.bin_weights = nn.Parameter( torch.rand( color_channel, nb_bin, requires_grad = True ) )\n",
    "        \n",
    "\n",
    "    def forward( self, x ):\n",
    "        # x.size() -> [4,3,32,32] = batch_size, nb_channels, width, height\n",
    "        # print( \"Size X for hist : \", x.size() )\n",
    "        nb_pixels = float( x.size(2)*x.size(3) )\n",
    "        hist = torch.Tensor( x.size(0), x.size(1), self.nb_bin ).to(device)\n",
    "\n",
    "        for b, x1 in enumerate( x ) :\n",
    "            for c, x2 in enumerate( x1 ) :\n",
    "                for h in range( self.nb_bin ):\n",
    "                    hist[b,c,h] = ( torch.exp( ( x2.sub( self.means[h] ) ).pow(2) * self.neg_inv_sq_sigma ) ).sum()\n",
    "            hist[b] *= self.bin_weights / nb_pixels\n",
    "            \n",
    "        # print( \"hist weights : \", self.bin_weights )\n",
    "        # return [batch_size, nb_channels, nb_bin]\n",
    "        return hist\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prototype faster we use a basic list to define a neural net architecture (basic CNN for now).\n",
    "Each element of the list represents a layer.\n",
    "Layers are defined in the order in which they are executed.\n",
    "Similar to nn.Sequential but slightly more compact (...but with less options now) and we don't have to compute all the numbers for input or output\n",
    "\n",
    "One layer is composed of a name and optionally some parameters.\n",
    "Currently available layers:\n",
    "- \"In\", number_of_input_for_the_next_layer. In Must be the first layer!\n",
    "- \"Conv2\", number_of_output, kernel_size\n",
    "- \"MaxPool2\", kernel_size\n",
    "- \"AvgPool2\", kernel_size\n",
    "- \"Drop\", probability\n",
    "- \"ReLu\"\n",
    "- \"View\"\n",
    "- \"Linear\", number_of_output\n",
    "- \"GaussHist\", color_channel, number of bins, min pixel value, max pixel value\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestNet(nn.Module):\n",
    "    def __init__(self, netConfig ):\n",
    "        super(TestNet, self).__init__()\n",
    "        \n",
    "        self.netConfig = netConfig\n",
    "        imgw = InImgSize\n",
    "        imgh = InImgSize\n",
    "        self.func = nn.ModuleList()  # if declared as [], the parameters of the function are not stored and we get the error : optimizer got an empty parameter list\n",
    "        self.viewSize = None         # we consider only one view layer in the net, for now\n",
    "\n",
    "        currOutput = 0               # number of outputs in the last computed layer\n",
    "        viewMul = 1\n",
    "        \n",
    "        if netConfig[0][0] != \"In\":\n",
    "            print( \"Error : the first item in the net configuration must be In\")\n",
    "            return\n",
    "        # TODO : add more test to check consistency between layers\n",
    "        \n",
    "        # compute all necessary layers using the declared netConfig\n",
    "        for i,l in enumerate( netConfig ):\n",
    "            layerName = l[0]\n",
    "            param1 = None if len(l) < 2 else l[1]\n",
    "            if layerName == \"In\" and i==0 :\n",
    "                print( \"In : \", param1 )\n",
    "                currOutput = param1\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            elif layerName == \"GaussHist\" and len(l)>4 :\n",
    "                print( \"GaussHist : \", param1, \", \", l[2], \", \", l[3], \", \", l[4] )\n",
    "                self.func.append( GaussianHistogram( param1, l[2], l[3], l[4] ) )\n",
    "                currOutput = l[2]\n",
    "                viewMul = param1\n",
    "            elif layerName == \"Conv2\" and len(l)>2 :\n",
    "                print( \"Conv2 : \", currOutput,\",\", param1,\",\", l[2] )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.Conv2d( currOutput, param1, l[2] ) )\n",
    "                currOutput = param1\n",
    "                imgw = imgw - l[2] + 1\n",
    "                imgh = imgh - l[2] + 1\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"AvgPool2\" :\n",
    "                print( \"AvgPool2 : \", param1 )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.AvgPool2d( param1, param1 ) )\n",
    "                imgw = imgw / 2\n",
    "                imgh = imgh / 2\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"MaxPool2\" :\n",
    "                print( \"MaxPool2 : \", param1 )\n",
    "                # TODO : add handling of stride, dilation and padding\n",
    "                self.func.append( nn.MaxPool2d( param1, param1 ) )\n",
    "                imgw = imgw / 2\n",
    "                imgh = imgh / 2\n",
    "                viewMul = imgw * imgh\n",
    "            elif layerName == \"Drop\" :\n",
    "                print( \"Drop : \", param1 )\n",
    "                self.func.append( nn.Dropout( p=param1 ) )\n",
    "            elif layerName == \"Linear\" :\n",
    "                print( \"Linear : \", int(currOutput),\",\", int(param1) )\n",
    "                self.func.append( nn.Linear( int(currOutput), int(param1) ) )\n",
    "                currOutput = param1\n",
    "            elif layerName == \"ReLu\" :\n",
    "                print( \"ReLu\" )\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            elif layerName == \"View\" :\n",
    "                currOutput = currOutput * viewMul\n",
    "                print( \"View : \", -1, \",\", int(currOutput) )\n",
    "                self.viewSize = currOutput\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "            else :\n",
    "                print( \"Unknown layer : \", layerName )\n",
    "                self.func.append( None )    # not a Module, so it cannot be added in the List\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i,layer in enumerate( self.netConfig ) :\n",
    "            if self.func[i] != None :\n",
    "                x = self.func[i]( x )\n",
    "            elif layer[0] == \"View\" :\n",
    "                x = x.view( -1, int(self.viewSize) )\n",
    "            elif layer[0] == \"ReLu\" :\n",
    "                x = F.relu( x )\n",
    "            elif layer[0] == \"In\" :\n",
    "                None\n",
    "            else :\n",
    "                print(\"Unknown Function..\")\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    [[\"In\",3],\n",
    "    [\"GaussHist\",3,10,min_val,max_val],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"GaussHist\",10,10,0.,1.],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"GaussHist\",10,20,0.,1.],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",80],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",40],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",30],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",20],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "\n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"Drop\",0.1],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",50],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",40],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "    \n",
    "    [[\"In\",3],\n",
    "    [\"Conv2\",10,5],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"Conv2\",10,3],\n",
    "    [\"ReLu\"],\n",
    "    [\"MaxPool2\",2],\n",
    "    [\"View\"],\n",
    "    [\"Linear\",80],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",60],\n",
    "    [\"ReLu\"],\n",
    "    [\"Linear\",len(classes)]],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_architecture = 0\n",
    "best_acc = 0.0\n",
    "best_loss = 999\n",
    "\n",
    "for archi, netConfig in enumerate(architectures):\n",
    "    net = TestNet( netConfig )\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam( net.parameters(), lr=LearningRate )\n",
    "    # optimizer = optim.SGD(net.parameters(), lr=LearningRate, momentum=0.9)\n",
    "\n",
    "    best_state = copy.deepcopy( net.state_dict() )\n",
    "    start_time = time.time()\n",
    "    for epoch in range( NbEpochsMax ):\n",
    "\n",
    "        # training phase \n",
    "        mean_loss = 0.\n",
    "        nb_mean = 0\n",
    "        for i, data in enumerate( trainloader, 0 ):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # print( \"parameters before : \", list( net.parameters() ) )\n",
    "\n",
    "            outputs = net( inputs )\n",
    "            loss = criterion( outputs, labels )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss = loss.item()\n",
    "            mean_loss += running_loss\n",
    "            nb_mean += 1\n",
    "            \n",
    "            # print( \"parameters after : \", list( net.parameters() ) )\n",
    "            print('[Epoch %3d, %4d] loss: %.3f' % (epoch, i, running_loss) )\n",
    "\n",
    "        mean_loss /= float(nb_mean)\n",
    "        \n",
    "        # test phase\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for data in testloader:\n",
    "                images, labels = data[0].to(device), data[1].to(device)\n",
    "                outputs = net( images )\n",
    "                _, predicted = torch.max( outputs.data, 1 )\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            acc = 100 * correct / total\n",
    "            epoch_time = time.time() - start_time\n",
    "            print('[Epoch %3d] acc: %.3f -- time: %d' % (epoch, acc, epoch_time) )\n",
    "\n",
    "            if acc > best_acc or (acc == best_acc and mean_loss < best_loss):\n",
    "                print(\"Backing up the network...\")\n",
    "                best_acc = acc\n",
    "                best_loss = mean_loss\n",
    "                best_state = copy.deepcopy( net.state_dict() )\n",
    "                best_architecture = archi\n",
    "                torch.save( net, './TahitiFlowerBest.pt' )\n",
    "\n",
    "    computation_time = time.time() - start_time\n",
    "    print('Architecture {} training finished -- {:.0f}m {:.0f}s'.format( archi, computation_time // 60, computation_time % 60) )\n",
    "\n",
    "print(\"Reloading the best net : \", best_architecture )\n",
    "net = torch.load( './TahitiFlowerBest.pt' )\n",
    "net.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow( img ):\n",
    "    # need to put color channel at the end for matplotlib\n",
    "    image = img.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Un-normalize\n",
    "    image = np.array(image_std) * image + np.array(image_means)\n",
    "    \n",
    "    plt.imshow( image )\n",
    "    plt.show()\n",
    "\n",
    "# show all images in a batch\n",
    "dataiter = iter( testloader )\n",
    "images, labels = dataiter.next()\n",
    "imshow( torchvision.utils.make_grid(images) )\n",
    "\n",
    "print( 'GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(BatchSize)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net( images.to(device) )\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(BatchSize)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(nbClasses))\n",
    "class_total = list(0. for i in range(nbClasses))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(nbClasses):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(nbClasses):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :\n",
    "- https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html\n",
    "- https://medium.com/datadriveninvestor/creating-a-pytorch-image-classifier-da9db139ba80\n",
    "- http://dde.binghamton.edu/download/model_hist/\n",
    "- ...\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
